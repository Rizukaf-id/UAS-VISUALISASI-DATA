{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ebef035-eddc-4889-a144-e61f6f6433c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pdp\n",
    "import cloudscraper\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--ignore-certificate-errors')\n",
    "# options.add_argument('--incognito')\n",
    "# options.add_argument('--headless')\n",
    "# driver = webdriver.Chrome(\"/usr/lib/chromium-browser/chromedriver\", chrome_options=options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "863ec232-d786-487e-9a1d-5f6badaba33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.transfermarkt.co.id/bayer-04-leverkusen/startseite/verein/15\n",
      "Bayer 04 Leverkusen - Profil Klub\n",
      "Bayer 04 Leverkusen - Profil KlubTransfermarkt.co.idhttps://www.transfermarkt.co.id › startseite › verein\n",
      "\n",
      "https://sport.detik.com/sepakbola/liga-jerman/d-7362082/heboh-rumor-bayer-leverkusen-mau-rekrut-cristiano-ronaldo\n",
      "Heboh Rumor Bayer Leverkusen Mau Rekrut Cristiano Ronaldo\n",
      "Heboh Rumor Bayer Leverkusen Mau Rekrut Cristiano Ronaldodetiksporthttps://sport.detik.com › Sepakbola › Liga Jerman\n",
      "\n",
      "https://id.wikipedia.org/wiki/Bayer_04_Leverkusen\n",
      "Bayer 04 Leverkusen - Wikipedia bahasa Indonesia ...\n",
      "Bayer 04 Leverkusen - Wikipedia bahasa Indonesia ...Wikipediahttps://id.wikipedia.org › wiki › Bayer_04_Leverkusen\n",
      "\n",
      "https://en.wikipedia.org/wiki/Bayer_04_Leverkusen\n",
      "Bayer 04 Leverkusen\n",
      "Bayer 04 LeverkusenWikipediahttps://en.wikipedia.org › B...\n",
      "\n",
      "https://www.bayer04.de/en-us\n",
      "Bayer 04 Leverkusen Fußball GmbH | bayer04.de\n",
      "Bayer 04 Leverkusen Fußball GmbH | bayer04.deBayer 04 Leverkusen Fußball GmbHhttps://www.bayer04.de › en-us\n",
      "\n",
      "https://www.goal.com/id/tim/bayer-leverkusen/7ad69ngbpjuyzv96drf8d9sn2\n",
      "Ikhtisar Bayer Leverkusen\n",
      "Ikhtisar Bayer LeverkusenGoal.comhttps://www.goal.com › tim › bayer-leverkusen\n",
      "\n",
      "https://www.bola.net/tag/bayer-leverkusen/\n",
      "Kumpulan Berita Bayer Leverkusen Terbaru\n",
      "Kumpulan Berita Bayer Leverkusen TerbaruBola.nethttps://www.bola.net › tag › bayer-leverkusen\n",
      "\n",
      "https://www.instagram.com/bayer04fussball/\n",
      "Bayer 04 Leverkusen (@bayer04fussball)\n",
      "Bayer 04 Leverkusen (@bayer04fussball)Instagramhttps://www.instagram.com › bayer04fussball\n",
      "\n",
      "https://www.detik.com/tag/bayer-leverkusen\n",
      "Berita dan Informasi Bayer leverkusen Terkini dan Terbaru ...\n",
      "Berita dan Informasi Bayer leverkusen Terkini dan Terbaru ...Detikcomhttps://www.detik.com › tag › bayer-leverkusen\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# webdriver.Chrome()\n",
    "# path = \"C:/Users/HP ENVY/.cache/selenium/chromedriver/win32/112.0.5615.49/chromedriver.exe\"\n",
    "# path = (\"C:/Users/HP ENVY/OWASP ZAP/webdriver/windows/32/chromedriver.exe\")\n",
    "# path = \"C:/Program Files/Google/Chrome/Application/chrome.exe\"\n",
    "# path = \"D:/DOWNLOADS/chromedriver-win64/chromedriver-win64/chromedriver.exe\"\n",
    "path = \"chromedriver-win64/chromedriver-win64/chromedriver.exe\"\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "service = Service(path)\n",
    "# Chrome(options=chrome_options, executable_path='path_to_chromedriver')\n",
    "# browser = webdriver.Chrome(service = service)\n",
    "browser = webdriver.Chrome(options=chrome_options, service = service)\n",
    "# browser = webdriver.Chrome(service = service)\n",
    "# browser.get('https://1xbet.whoscored.com')\n",
    "browser.get('https://www.google.com')\n",
    "search_box = browser.find_element('id','APjFqb')\n",
    "# search_box = browser.find_element('class','gLFyf')\n",
    "\n",
    "search_box.clear()\n",
    "search_box.send_keys(\"bayer leverkusen\")\n",
    "search_box.submit()\n",
    "\n",
    "# search_btn = browser.find_element('class','gNO89b')\n",
    "# search_btn.click()\n",
    "\n",
    "page = browser.page_source\n",
    "soup = BeautifulSoup(page,'html.parser') \n",
    "\n",
    "rows = soup.findAll(\"div\", {\"class\":\"N54PNb BToiNc cvP2Ce\"})\n",
    "\n",
    "for row in rows:\n",
    "    \n",
    "# \"span\",  :\"\"\n",
    "    link = row.find(\"a\").get('href')\n",
    "    title = row.find(\"h3\", {\"class\":\"LC20lb MBeuO DKV0Md\"}).text\n",
    "    texts = row.find(\"span\",{\"class\":\"\"}).text\n",
    "    print(link)\n",
    "    print(title)\n",
    "    print(texts)\n",
    "    print(\"\")\n",
    "# print(browser.page_source)\n",
    "# print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7341f0f6-ded8-48d2-ba63-a056c8ccefd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_url = \"http://www.imdb.com/search/title?sort=num_votes,desc&start=1&title_type=feature&year=2020,2024\"\n",
    "\n",
    "# uClient = uReq(my_url)\n",
    "# page_html = uClient.read()\n",
    "# uClient.close()\n",
    "\n",
    "scraper = cloudscraper.create_scraper(delay=10, browser=\"chrome\") \n",
    "content = scraper.get(my_url).text \n",
    "# content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3554ad59-25e7-44ab-84b1-8d65b5222d9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len movie 25\n",
      "Spider-Man: No Way Home,2021,148,PG-13\n",
      "Dune,2021,155,PG-13\n",
      "The Batman,2022,176,PG-13\n",
      "Oppenheimer,2023,180,R\n",
      "Top Gun: Maverick,2022,130,PG-13\n",
      "Don't Look Up,2021,138,R\n",
      "Tenet,2020,150,PG-13\n",
      "The Kashmir Files,2022,170,Not Rated\n",
      "Barbie,2023,114,PG-13\n",
      "Everything Everywhere All at Once,2022,139,R\n",
      "Avatar: The Way of Water,2022,192,PG-13\n",
      "Doctor Strange in the Multiverse of Madness,2022,126,PG-13\n",
      "No Time to Die,2021,163,PG-13\n",
      "Glass Onion,2022,139,PG-13\n",
      "Zack Snyder's Justice League,2021,242,R\n",
      "Bullet Train,2022,127,R\n",
      "Shang-Chi and the Legend of the Ten Rings,2021,132,PG-13\n",
      "Dune: Part Two,2024,166,PG-13\n",
      "Free Guy,2021,115,PG-13\n",
      "Black Widow,2021,134,PG-13\n",
      "The Suicide Squad,2021,132,R\n",
      "Thor: Love and Thunder,2022,118,PG-13\n",
      "The Menu,2022,107,R\n",
      "Eternals,2021,156,PG-13\n",
      "Guardians of the Galaxy Vol. 3,2023,150,PG-13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "containers = BeautifulSoup(content, \"html.parser\")\n",
    "# page_soup\n",
    "\n",
    "filename= \"imdb_m.csv\"\n",
    "f= open(filename, \"w\")\n",
    "\n",
    "headers= \"Name, Year, Durasi(Menit), Rating \\n\"\n",
    "f.write(headers)\n",
    "\n",
    "\n",
    "# for container in containers:\n",
    "    # name= container.img[\"alt\"]\n",
    "    # name = container.findAll(\"span\", {\"class\": \"ipc-title ipc-title--base ipc-title--title ipc-title-link-no-icon ipc-title--on-textPrimary sc-b189961a-9 iALATN dli-title\"})\n",
    "#     year_mov= container.findAll(\"span\", {\"class\": \"lister-item-year\"})\n",
    "#     year=year_mov[0].text\n",
    "#     runtime_mov= container.findAll(\"span\", {\"class\": \"runtime\"})\n",
    "#     runtime=runtime_mov[0].text\n",
    "    \n",
    "#     print(name + \",\" + year + \",\" + runtime +  \"\\n\")\n",
    "#     f.write(name + \",\" + year + \",\" + runtime  + \"\\n\")\n",
    "\n",
    "movies = containers.find_all(\"div\", {\"class\": \"sc-b189961a-0 hBZnfJ\"})\n",
    "print(\"len movie\", len(movies))\n",
    "\n",
    "# sc-b189961a-0 hBZnfJ\n",
    "# sc-b189961a-8 kLaxqf dli-title-metadata-item\n",
    "for movie in movies:\n",
    "    name = re.sub(r\"\\d+. \",\"\", movie.find(\"h3\", {\"class\": \"ipc-title__text\"}).text)\n",
    "    detil_line = movie.findAll(\"span\", {\"class\": \"sc-b189961a-8 kLaxqf dli-title-metadata-item\"})\n",
    "    if len(detil_line) > 2:        \n",
    "        year_movie = detil_line[0].text\n",
    "        durasi = detil_line[1].text\n",
    "        durasi = durasi.split(\" \")\n",
    "        if len(durasi) > 1:\n",
    "            menit = int(durasi[0].replace(\"h\",\"\")) * 60 + int(durasi[1].replace(\"m\",\"\"))   \n",
    "        else:\n",
    "            menit = int(durasi[0].replace(\"h\",\"\")) * 60 \n",
    "        # durasi_menit = \n",
    "        rating = detil_line[2].text\n",
    "    elif len(detil_line) > 1:\n",
    "        year_movie = detil_line[0].text\n",
    "        durasi = detil_line[1].text\n",
    "        durasi = durasi.split(\" \")\n",
    "        if len(durasi) > 1:\n",
    "            menit = int(durasi[0].replace(\"h\",\"\")) * 60 + int(durasi[1].replace(\"m\",\"\"))   \n",
    "        else:\n",
    "            menit = int(durasi[0].replace(\"h\",\"\")) * 60 \n",
    "    else:\n",
    "        year_movie = detil_line[0].text\n",
    "        \n",
    "    print(name + \",\" + year_movie + \",\" + str(menit) + \",\" + rating)  \n",
    "    f.write(name + \",\" + year_movie + \",\" + str(menit) + \",\" + rating + \"\\n\")\n",
    "    \n",
    "    \n",
    "# from urllib.request import urlopen as uReq\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pdp\n",
    "# import cloudscraper\n",
    "# import re\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver import Chrome\n",
    "# from selenium.webdriver.chrome.options import Optionsf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4afc122-3c4a-42d6-9b76-62236cd1cf5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#FIREFOX VERSION\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pdp\n",
    "import re\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "# from selenium.webdriver import Chrome\n",
    "from selenium.webdriver import Firefox\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# the first page to be accessed \n",
    "my_url = \"http://www.imdb.com/search/title?sort=num_votes,desc&start=1&title_type=feature&year=2024,2024\"\n",
    "\n",
    "# IF YOU WANT TO DO HEADLESS BROWSER, use codes below\n",
    "# options = Options()\n",
    "# options.headless = True\n",
    "# browser = webdriver.Firefox(options=options)\n",
    "\n",
    "\n",
    "# THIS IS FOR NORMAL BROWSER SESSION (NOT HEADLESS\n",
    "# define browser to get the first URL\n",
    "browser = webdriver.Firefox() \n",
    "\n",
    "# define browser to get the second/detail URL\n",
    "browser2 = webdriver.Firefox()\n",
    "\n",
    "# check file availability and content is not empty\n",
    "filename = \"imdb_primary_data.csv\"\n",
    "filename2 = \"imdb_secondary_data.csv\"\n",
    "\n",
    "def visualize_data():\n",
    "    print(\"Visualize Something\")\n",
    "    \n",
    "\n",
    "if os.path.isfile(filename) and os.path.getsize(filename) > 0:   \n",
    "   \n",
    "    os.remove(filename)\n",
    "    os.remove(filename2)\n",
    "    \n",
    "#     print(\"The file exists and is not empty.\")\n",
    "    \n",
    "#     visualize_data()\n",
    "#     # Below you can do whatever you want to visualize the data\n",
    "    \n",
    "# else:\n",
    "#     print(\"The file does not exist or is empty.\")\n",
    "    \n",
    "\n",
    "    f = open(filename, \"w\")\n",
    "    fheaders = \"Name,Year,Durasi(Menit),Rating\\n\"\n",
    "    f2 = open(filename2, \"w\")\n",
    "    f2headers = \"Name,Budget,Gross_US,Opening_Week,Open_Week_Date,Gross_World\\n\"\n",
    "    \n",
    "    f.write(fheaders)\n",
    "    f2.write(f2headers)\n",
    "    \n",
    "    try:\n",
    "        # open session for first URL\n",
    "        browser.get(my_url)\n",
    "        \n",
    "        # We are going to have 2 different actions for \"browser\"\n",
    "        # 1. Looking for primary data for each movie in the LIST\n",
    "        # 2. Looking for LIST of movies based on the search and links to detail page\n",
    "        #    and then run \"browser2\" to get the page using the link and extract \n",
    "        #    additional data for each movie in the LIST\n",
    "        \n",
    "\n",
    "        # ACTION 1\n",
    "        first_page = BeautifulSoup(browser.page_source ,'html.parser')\n",
    "        movies = first_page.find_all(\"div\", {\"class\":\"sc-b189961a-0 hBZnfJ\"})\n",
    "        \n",
    "        count2 = 0\n",
    "        print(\"Primary Data\")\n",
    "        print(\"-----------------------------------\")\n",
    "        for movie in movies:\n",
    "            count2 += 1\n",
    "            menit = 0\n",
    "            rating = \"Not Rated\"\n",
    "            name = re.sub(r\"\\d+. \",\"\", movie.find(\"h3\", {\"class\": \"ipc-title__text\"}).text)\n",
    "            detil_line = movie.findAll(\"span\", {\"class\": \"sc-b189961a-8 kLaxqf dli-title-metadata-item\"})\n",
    "            if len(detil_line) > 2:        \n",
    "                year_movie = detil_line[0].text\n",
    "                durasi = detil_line[1].text\n",
    "                durasi = durasi.split(\" \")\n",
    "                if len(durasi) > 1:\n",
    "                    menit = int(durasi[0].replace(\"h\",\"\")) * 60 + int(durasi[1].replace(\"m\",\"\"))   \n",
    "                else:\n",
    "                    menit = int(durasi[0].replace(\"h\",\"\")) * 60 \n",
    "                # durasi_menit = \n",
    "                rating = detil_line[2].text\n",
    "            elif len(detil_line) > 1:\n",
    "                year_movie = detil_line[0].text\n",
    "                durasi = detil_line[1].text\n",
    "                durasi = durasi.split(\" \")\n",
    "                if len(durasi) > 1:\n",
    "                    menit = int(durasi[0].replace(\"h\",\"\")) * 60 + int(durasi[1].replace(\"m\",\"\"))   \n",
    "                else:\n",
    "                    menit = int(durasi[0].replace(\"h\",\"\")) * 60 \n",
    "            else:\n",
    "                year_movie = detil_line[0].text        \n",
    "        \n",
    "            print(\"-----------------------------------\")\n",
    "            print(name + \",\" + year_movie + \",\" + str(menit) + \",\" + rating)  \n",
    "            f.write(name + \",\" + year_movie + \",\" + str(menit) + \",\" + rating + \"\\n\")\n",
    "        \n",
    "        # ACTION 2\n",
    "        #\n",
    "        # TECHNIQUE MENUNGGU SAMPAI SEMUA ELEMEN KE-LOAD\n",
    "        # variasi 1\n",
    "        # element_present = EC.presence_of_all_elements_located((By.CLASS_NAME, 'sc-b189961a-0 hBZnfJ'))\n",
    "        # WebDriverWait(browser, 4).until(element_present)\n",
    "\n",
    "        # variasi 2\n",
    "        # element_preset = EC.presence_of_all_elements_located((By.XPATH, \"//div[@class='sc-b189961a-0 hBZnfJ']\"))\n",
    "        # elems = WebDriverWait(browser,10).until(element_preset)\n",
    "\n",
    "        # variasi 3\n",
    "        # element_preset = EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div[class='.sc-b189961a-0 hBZnfJ']\"))\n",
    "        # elems = WebDriverWait(browser,10).until(element_preset)\n",
    "\n",
    "        ## TECHNIQUE TANPA MENUNGGU , ASUMSI KE-LOAD SEMUA\n",
    "        # variasi 1\n",
    "        # elems = browser.find_elements_by_xpath(\"//div@class='sc-eYdvao.kvdWiq'\")\n",
    "        # links = [elem.get_attribute('href') for elem in elems]\n",
    "\n",
    "        # variasi 2    \n",
    "        links = browser.find_elements(By.XPATH, '//div[@class=\"sc-b189961a-0 hBZnfJ\"]')\n",
    "\n",
    "        count = 0\n",
    "        print(\"-----------------------------------\")\n",
    "        print(\"-----------------------------------\")\n",
    "        print(\"SECONDARY DATA\")\n",
    "        print(\"panjang \", len(links))\n",
    "        movie_titles = browser.find_elements(By.XPATH, '//h3[@class=\"ipc-title__text\"]')\n",
    "        # print(\"panjang judul:\", len(movie_titles)-1)\n",
    "        \n",
    "        # break\n",
    "        \n",
    "        for link in links:\n",
    "            title = re.sub(r\"\\d+. \",\"\", movie_titles[count].text)\n",
    "            print(\"judul ke-\" + str(count+1) + \": \" + title)\n",
    "            count += 1\n",
    "            budget_num = 0\n",
    "            gross_us_num = 0\n",
    "            open_week_rev_num = 0\n",
    "            open_week_date_std = \"1900-01-01 00:00:00\"\n",
    "            gross_world_num = 0\n",
    "            # # link = row.find_element(By.XPATH, '//a[@href=\"'+url+'\"]')\n",
    "            # # link = row.find_element(By.XPATH, '//a[@class=\"ipc-title-link-wrapper\"]').get_attribute('href')\n",
    "            # link = row.find_element(By.XPATH, '//div[@class=\"ipc-title ipc-title--base ipc-title--title ipc-title-link-no-icon ipc-title--on-textPrimary sc-b189961a-9 iALATN dli-title\"]/a').get_attribute('href')\n",
    "            # # link = row.fine_element(By.CSS_SELECTOR, \"a\")\n",
    "            print(\"----------------------\")\n",
    "            print(count, link.find_element(By.CSS_SELECTOR, \"a\").get_attribute('href'), \"\\n\")\n",
    "            browser2.get(link.find_element(By.CSS_SELECTOR, \"a\").get_attribute('href'))\n",
    "\n",
    "            # BOX OFFICE DATA ON THE 2ND URL\n",
    "            det_page = browser2.page_source        \n",
    "            container_rows = BeautifulSoup(det_page, \"html.parser\")        \n",
    "            box_office_elements = container_rows.find(\"div\",{\"data-testid\":\"title-boxoffice-section\"})\n",
    "            if box_office_elements is not None:\n",
    "                det_movie = box_office_elements.find_all(\"span\",{\"class\":\"ipc-metadata-list-item__list-content-item\"})\n",
    "\n",
    "                if len(det_movie) > 4:\n",
    "\n",
    "                    budget = det_movie[0].text\n",
    "                    gross_us = det_movie[1].text\n",
    "                    open_week_rev = det_movie[2].text\n",
    "                    open_week_date = det_movie[3].text            \n",
    "                    gross_world = det_movie[4].text\n",
    "\n",
    "                    print(\"budget = \" + budget)\n",
    "                    print(\"gross_us = \" + gross_us)\n",
    "                    print(\"opening_week_rev = \" + open_week_rev)\n",
    "                    print(\"opening_week_date = \" + open_week_date)\n",
    "                    print(\"gross_world = \" + gross_world)\n",
    "\n",
    "                    # print(det_page)\n",
    "                    # print(\"\\n\")\n",
    "                    print(\"=====================================\")\n",
    "                    budget_num = int(re.sub(\"[A-Z£€₹$,()a-z]\",\"\",budget))\n",
    "                    gross_us_num = int(re.sub(\"[A-Z£€₹$,()a-z]\",\"\",gross_us))\n",
    "                    open_week_rev_num = int(re.sub(\"[A-Z£€₹$,()a-z]\",\"\",open_week_rev))\n",
    "                    open_week_date_std = datetime.strptime(open_week_date, \"%b %d, %Y\")\n",
    "                    gross_world_num = int(re.sub(\"[A-Z£€₹$,()a-z]\",\"\",gross_world))\n",
    "\n",
    "                    print(\"Data has been formatted to standard\")\n",
    "                    print(\"-----------------------------------\")\n",
    "                    print(\"budget =\", budget_num)\n",
    "                    print(\"gross_us =\" , gross_us_num)\n",
    "                    print(\"opening_week_rev =\" , open_week_rev_num)\n",
    "                    print(\"opening_week_date =\", open_week_date_std)\n",
    "                    print(\"gross_world =\", gross_world_num)\n",
    "            \n",
    "            # UNTUK TEST SAJA\n",
    "            # break\n",
    "            \n",
    "            f2.write(str(title) + \",\" + str(budget_num) + \",\" + str(gross_us_num) + \",\" + str(open_week_rev_num) + \",\" + str(open_week_date_std) + \",\" + str(gross_world_num) + \"\\n\")\n",
    "\n",
    "            # f2.write(budget_num + \",\" + gross_us_num + \",\" + open_week_rev_num + \",\" + open_week_date_std + \",\" + gross_world_num + \"\\n\")  \n",
    "       \n",
    "    except Exception as E:\n",
    "        print(E)\n",
    "\n",
    "        f.close()\n",
    "        f2.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32616bd8-9b93-4a3d-a1f9-b3993f35b4b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'imdb_primary_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(fn3)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Read CSV files into dataframes\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(fn2)\n\u001b[0;32m     18\u001b[0m merged \u001b[38;5;241m=\u001b[39m df1\u001b[38;5;241m.\u001b[39mmerge(df2,on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Kuliah\\SEMESTER 6\\Visualisasi Data\\UAS\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Kuliah\\SEMESTER 6\\Visualisasi Data\\UAS\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\Kuliah\\SEMESTER 6\\Visualisasi Data\\UAS\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Kuliah\\SEMESTER 6\\Visualisasi Data\\UAS\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\Kuliah\\SEMESTER 6\\Visualisasi Data\\UAS\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'imdb_primary_data.csv'"
     ]
    }
   ],
   "source": [
    "# THE FOLLOWING CODE IS TO MERGE 2 IMDB_DATA CSV FILES\n",
    "# INTO ONE CSV BASED ON NAME\n",
    "# NAME IS ADDED TO SECONDARY DATA MANUALLY\n",
    "\n",
    "import pandas as pd\n",
    "fn1 = 'imdb_primary_data.csv'\n",
    "fn2 = 'imdb_secondary_data.csv'\n",
    "\n",
    "fn3 = 'imdb_combined_data2.csv'\n",
    "\n",
    "if os.path.isfile(fn3) and os.path.getsize(fn3) > 0:      \n",
    "    os.remove(fn3)\n",
    "    \n",
    "# Read CSV files into dataframes\n",
    "df1 = pd.read_csv(fn1)\n",
    "df2 = pd.read_csv(fn2)\n",
    "\n",
    "merged = df1.merge(df2,on='Name')\n",
    "merged.to_csv(\"imdb_combined_data2.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f5d22e5-3f72-4520-8b29-d9a10802124a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'imdb_combined_data2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Read CSV files into dataframes\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimdb_combined_data2.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# df.astype(\"string\")\u001b[39;00m\n\u001b[0;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mkeys()\n",
      "File \u001b[1;32md:\\Kuliah\\SEMESTER 6\\Visualisasi Data\\UAS\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Kuliah\\SEMESTER 6\\Visualisasi Data\\UAS\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\Kuliah\\SEMESTER 6\\Visualisasi Data\\UAS\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Kuliah\\SEMESTER 6\\Visualisasi Data\\UAS\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\Kuliah\\SEMESTER 6\\Visualisasi Data\\UAS\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'imdb_combined_data2.csv'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Read CSV files into dataframes\n",
    "df = pd.read_csv('imdb_combined_data2.csv')\n",
    "# df.astype(\"string\")\n",
    "\n",
    "df.keys()\n",
    "\n",
    "df['Rating'] = df['Rating'].astype(\"string\")\n",
    "df['Rating']\n",
    "\n",
    "df['Name'] = df['Name'].astype(\"string\")\n",
    "df['Name']\n",
    "\n",
    "df['Year'] = pd.to_numeric(df['Year'])\n",
    "df['Year']\n",
    "\n",
    "df['Budget']\n",
    "df_sorted = df.sort_values(by=['Budget'])\n",
    "df_sel = df[['Rating','Gross_US', 'Gross_World']]\n",
    "df_sel\n",
    "\n",
    "# drop rows with all zeros techique 1\n",
    "df_sel = df_sel.loc[df_sel['Gross_US'] * df_sel['Gross_World'] != 0]\n",
    "\n",
    "# drop rows with all zeros techique 2\n",
    "\n",
    "hsl = df_sel.loc[(df_sel[['Gross_US', 'Gross_World']] != 0).all(axis=1)]\n",
    "hsl\n",
    "\n",
    "\n",
    "df_sel2 = df[['Gross_US','Gross_World','Rating','Budget']]\n",
    "df_sel2['Gross_US'] = df_sel2['Gross_US']/1000000\n",
    "df_sel2['Gross_World'] = df_sel2['Gross_World']/1000000\n",
    "\n",
    "chart_data2 = pd.DataFrame(df_sel2, columns=[\"Gross_US\", \"Gross_World\", \"Rating\", \"Budget\"])\n",
    "# st.scatter_chart\n",
    "# df_sorted\n",
    "# sorting\n",
    "# label = df_sel.Rating.unique()\n",
    "# label\n",
    "\n",
    "hsl = hsl.groupby(['Rating']).sum()\n",
    "hsl.index\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
